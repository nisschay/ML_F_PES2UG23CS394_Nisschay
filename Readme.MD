---

# ğŸ“Š ML-Lab

This repository contains my **Machine Learning Laboratory coursework**, including weekly assignments and future mini-projects.
It serves as a personal record of my work, experiments, and learning progress throughout the course.

---

## ğŸ“‚ Repository Structure

```
ML-Lab/
â”œâ”€â”€ ML_LAB1_Assignment/
â”‚   â”œâ”€â”€ ML_LAB_1.pdf                  # Week 1 lab instructions
â”‚   â”œâ”€â”€ ML_Lab_Assignment_1_1.ipynb   # Notebook for Assignment 1.1
â”‚   â”œâ”€â”€ ML_Lab_Assignment_1_2.ipynb   # Notebook for Assignment 1.2
â”‚   â”œâ”€â”€ customer_churn_data.csv       # Dataset for classification task
â”‚   â””â”€â”€ house_price_data.csv          # Dataset for regression task
â”œâ”€â”€ ML_LAB3_Assignment/
â”‚   â””â”€â”€ EC_F_PES2UG23CS394_Lab3.py    # Information Gain & Decision Tree implementation
â”œâ”€â”€ ML_LAB4_Assignment/
â”‚   â”œâ”€â”€ ML_LAB4.pdf                   # Week 4 lab instructions
â”‚   â”œâ”€â”€ ML_Lab4_1.ipynb               # Wine Quality Classification
â”‚   â””â”€â”€ ML_Lab4_2.ipynb               # Banknote Authentication Classification
â””â”€â”€ (Upcoming assignments & projects)
```

---

## ğŸ“Œ Contents

### **Week 1**

* **Topics Covered**:
  * Data loading and exploration with Pandas
  * Basic data preprocessing
  * Exploratory Data Analysis (EDA)
  * Building simple ML models for classification & regression
* **Datasets**:
  * *Customer Churn Data* â€“ for binary classification
  * *House Price Data* â€“ for regression analysis

### **Week 2**

* **Status**: âŒ No assignment (missed week)

### **Week 3**

* **Topics Covered**:
  * Information Theory fundamentals
  * Entropy calculation for datasets
  * Information Gain computation
  * Decision Tree attribute selection algorithms
  * PyTorch tensor operations for ML computations
* **Implementation**:
  * `get_entropy_of_dataset()` - Calculate dataset entropy using Shannon's formula
  * `get_avg_info_of_attribute()` - Compute weighted average information for attribute splits
  * `get_information_gain()` - Calculate information gain for feature selection
  * `get_selected_attribute()` - Select best attribute based on highest information gain
* **Datasets Tested**:
  * *Mushrooms Dataset* â€“ mushroom classification
  * *Nursery Dataset* â€“ nursery school ranking
  * *Tic-Tac-Toe Dataset* â€“ game outcome prediction

### **Week 4**

* **Topics Covered**:
  * Classification algorithms implementation and comparison
  * Manual vs Built-in classifier implementations
  * Hyperparameter tuning techniques
  * Model performance evaluation and analysis
* **Algorithms Implemented**:
  * **K-Nearest Neighbors (KNN)** - Both manual and built-in versions
  * **Logistic Regression** - Both manual and built-in implementations
  * **Decision Tree** - Both manual and built-in classifiers
  * **Voting Classifier** - Ensemble method combining multiple algorithms
* **Hyperparameter Optimization**:
  * **GridSearchCV** - Automated hyperparameter search
  * **Manual Search** - Custom hyperparameter tuning implementation
* **Datasets**:
  * *Wine Quality Dataset* â€“ Multi-class classification of wine quality
  * *Banknote Authentication Dataset* â€“ Binary classification for fraud detection
* **Performance Metrics**:
  * Accuracy, Precision, Recall, F1-Score
  * ROC-AUC for model comparison
  * Comprehensive performance analysis tables

### **Future Work**

* Additional weekly lab assignments
* One or more **mini-projects**, applying ML techniques to real-world datasets

---

## ğŸš€ Getting Started

### **1ï¸âƒ£ Clone the repository**

```bash
git clone https://github.com/nisschay/ML-Lab.git
cd ML-Lab
```

### **2ï¸âƒ£ Install dependencies**

It is recommended to use a virtual environment:

```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Open notebooks**

Launch Jupyter Notebook or JupyterLab:

```bash
jupyter notebook
```

### **4ï¸âƒ£ Run Week 3 code**

For the decision tree implementation:

```python
python ML_LAB3_Assignment/EC_F_PES2UG23CS394_Lab3.py
```

### **5ï¸âƒ£ Explore Week 4 assignments**

Navigate to the ML_LAB4_Assignment folder and open the Jupyter notebooks:

```bash
cd ML_LAB4_Assignment
jupyter notebook ML_Lab4_1.ipynb  # Wine Quality Analysis
jupyter notebook ML_Lab4_2.ipynb  # Banknote Authentication
```

---

## ğŸ›  Tech Stack

* **Python 3.10+**
* **Jupyter Notebook**
* **NumPy**, **Pandas**, **Matplotlib**, **Seaborn**
* **Scikit-Learn**
* **PyTorch** (added for Week 3)

---

## ğŸ“… Timeline

| Week         | Status      | Notes                                    |
| ------------ | ----------- | ---------------------------------------- |
| 1            | âœ… Completed | Introductory ML tasks                    |
| 2            | âŒ Missed    | No assignment                           |
| 3            | âœ… Completed | Information Gain & Decision Tree theory  |
| 4            | âœ… Completed | Classification algorithms & hyperparameter tuning |
| 5+           | â³ Pending   | Will be uploaded as completed           |
| Mini-Project | â³ Pending   | Planned for later in the semester       |

---

## ğŸ¯ Key Learning Outcomes

### Week 1
- Data manipulation and visualization techniques
- Basic ML model implementation and evaluation

### Week 3
- Understanding information theory in machine learning
- Implementing entropy and information gain calculations
- Attribute selection algorithms for decision trees
- Working with PyTorch tensors for ML computations

### Week 4
- Manual implementation of core classification algorithms
- Understanding the mathematics behind KNN, Logistic Regression, and Decision Trees
- Comparison between manual and built-in implementations
- Ensemble methods and voting classifiers
- Hyperparameter optimization strategies (GridSearchCV vs Manual Search)
- Comprehensive model evaluation using multiple metrics
- Performance analysis across different datasets and problem types

---

## ğŸ“œ License

This repository is intended for **academic and learning purposes only**.
Feel free to refer to the code, but **do not submit as your own work** if you are enrolled in a similar course.

---